{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGVypnlGK9X1"
      },
      "outputs": [],
      "source": [
        "!pip -q install pandas numpy scikit-learn xgboost joblib matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score,\n",
        "    confusion_matrix, roc_curve, precision_recall_curve,\n",
        "    balanced_accuracy_score, matthews_corrcoef\n",
        ")\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "WORKDIR = Path(\"/content\")\n",
        "DATA_DIR = WORKDIR / \"data\"\n",
        "OUT_DIR  = WORKDIR / \"outputs\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 200)"
      ],
      "metadata": {
        "id": "1fm7sOH9LaPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_head(df, title, n=5):\n",
        "    print(f\"\\n===== {title} (shape={df.shape}) =====\")\n",
        "    display(df.head(n))\n",
        "\n",
        "def plot_pr(y_true, y_proba, title):\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(rec, prec)\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc(y_true, y_proba, title):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion(y_true, y_proba, threshold, title):\n",
        "    y_pred = (np.asarray(y_proba) >= threshold).astype(int)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure()\n",
        "    plt.imshow(cm)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.xticks([0, 1], [0, 1])\n",
        "    plt.yticks([0, 1], [0, 1])\n",
        "    for (i, j), v in np.ndenumerate(cm):\n",
        "        plt.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_binary_plus(y_true, y_proba, threshold, name=\"model\"):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_pred = (np.asarray(y_proba) >= threshold).astype(int)\n",
        "    return {\n",
        "        \"model\": name,\n",
        "        \"threshold\": float(threshold),\n",
        "        \"pos_rate\": float(y_true.mean()),\n",
        "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
        "        \"balanced_accuracy\": float(balanced_accuracy_score(y_true, y_pred)),\n",
        "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
        "        \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
        "        \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
        "        \"mcc\": float(matthews_corrcoef(y_true, y_pred)),\n",
        "        \"roc_auc\": float(roc_auc_score(y_true, y_proba)) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "        \"pr_auc\": float(average_precision_score(y_true, y_proba)) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "        \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist()\n",
        "    }\n",
        "\n",
        "def pick_threshold_max_f1(y_true, y_proba):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
        "    thr = np.append(thr, 1.0)\n",
        "    f1s = (2 * prec * rec) / (prec + rec + 1e-12)\n",
        "    return float(thr[int(np.argmax(f1s))])\n",
        "\n",
        "def pick_threshold_for_min_recall(y_true, y_proba, min_recall=0.80):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
        "    thr = np.append(thr, 1.0)\n",
        "    ok = np.where(rec >= min_recall)[0]\n",
        "    if len(ok) == 0:\n",
        "        return float(thr[np.argmax(rec)])\n",
        "    best = ok[np.argmax(prec[ok])]\n",
        "    return float(thr[best])"
      ],
      "metadata": {
        "id": "1VgilWtdLdNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    print(\"Uploaded:\", fn)\n",
        "\n",
        "# Move uploaded zips/csvs into DATA_DIR\n",
        "for f in WORKDIR.glob(\"*.zip\"):\n",
        "    tgt = DATA_DIR / f.name\n",
        "    if not tgt.exists():\n",
        "        f.rename(tgt)\n",
        "\n",
        "for f in WORKDIR.glob(\"*.csv\"):\n",
        "    tgt = DATA_DIR / f.name\n",
        "    if not tgt.exists():\n",
        "        f.rename(tgt)\n",
        "\n",
        "# Unzip all Freddie zips\n",
        "for z in DATA_DIR.glob(\"*.zip\"):\n",
        "    print(\"Extracting:\", z.name)\n",
        "    with zipfile.ZipFile(z, \"r\") as zp:\n",
        "        zp.extractall(DATA_DIR)\n",
        "\n",
        "print(\"\\nDATA_DIR files:\")\n",
        "for p in sorted(DATA_DIR.glob(\"*\")):\n",
        "    if p.is_file():\n",
        "        print(\" -\", p.name)"
      ],
      "metadata": {
        "id": "yZekrk0HLgND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pipe(path):\n",
        "    return pd.read_csv(path, sep=\"|\", header=None, dtype=str, engine=\"python\")\n",
        "\n",
        "orig_files = sorted([p for p in DATA_DIR.glob(\"*\") if p.is_file() and \"orig\" in p.name.lower() and p.suffix.lower() in [\".txt\", \".csv\"]])\n",
        "perf_files = sorted([p for p in DATA_DIR.glob(\"*\") if p.is_file() and any(k in p.name.lower() for k in [\"svcg\", \"servicing\", \"perf\"]) and p.suffix.lower() in [\".txt\", \".csv\"]])\n",
        "\n",
        "if not orig_files or not perf_files:\n",
        "    raise FileNotFoundError(\"Could not find Freddie orig/perf files. Ensure Freddie zips were uploaded and extracted.\")\n",
        "\n",
        "orig_raw = pd.concat([read_pipe(p) for p in orig_files], ignore_index=True)\n",
        "perf_raw = pd.concat([read_pipe(p) for p in perf_files], ignore_index=True)\n",
        "\n",
        "print(\"orig_raw:\", orig_raw.shape, \"perf_raw:\", perf_raw.shape)\n",
        "\n",
        "orig_raw.columns = [f\"c{i}\" for i in range(orig_raw.shape[1])]\n",
        "perf_raw.columns = [f\"c{i}\" for i in range(perf_raw.shape[1])]\n",
        "\n",
        "# Map fields by position (Freddie sample layout)\n",
        "orig = orig_raw.rename(columns={\"c19\": \"loan_sequence_number\"}).copy()\n",
        "perf = perf_raw.rename(columns={\n",
        "    \"c0\": \"loan_sequence_number\",\n",
        "    \"c1\": \"monthly_reporting_period\",\n",
        "    \"c3\": \"current_loan_delinquency_status\",\n",
        "    \"c8\": \"zero_balance_code\"\n",
        "}).copy()\n",
        "\n",
        "perf[\"monthly_reporting_period\"] = pd.to_datetime(perf[\"monthly_reporting_period\"], format=\"%Y%m\", errors=\"coerce\")\n",
        "perf = perf[perf[\"monthly_reporting_period\"].notna()].copy()\n",
        "\n",
        "print_head(perf[[\"loan_sequence_number\",\"monthly_reporting_period\",\"current_loan_delinquency_status\",\"zero_balance_code\"]],\n",
        "           \"Freddie Perf - Key Columns\")"
      ],
      "metadata": {
        "id": "kgLd6cjvLikw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_dq(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    x = str(x).strip()\n",
        "    return int(x) if x.isdigit() else np.nan\n",
        "\n",
        "def to_num(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "perf = perf.sort_values([\"loan_sequence_number\",\"monthly_reporting_period\"]).copy()\n",
        "perf[\"dq\"] = perf[\"current_loan_delinquency_status\"].apply(map_dq)\n",
        "perf[\"zb\"] = to_num(perf[\"zero_balance_code\"])\n",
        "\n",
        "perf[\"is_dq\"] = (perf[\"dq\"].fillna(0) >= 1).astype(int)\n",
        "perf[\"is_serious_dq\"] = (perf[\"dq\"].fillna(0) >= 3).astype(int)\n",
        "perf[\"is_zb_bad\"] = perf[\"zb\"].isin([3,6,9]).astype(int)\n",
        "\n",
        "g = perf.groupby(\"loan_sequence_number\", sort=False)\n",
        "H = 6\n",
        "\n",
        "future_serious = pd.concat([g[\"is_serious_dq\"].shift(-k) for k in range(1, H+1)], axis=1)\n",
        "future_zb      = pd.concat([g[\"is_zb_bad\"].shift(-k) for k in range(1, H+1)], axis=1)\n",
        "valid = future_serious.notna().all(axis=1) & future_zb.notna().all(axis=1)\n",
        "\n",
        "perf[\"y_default_future_6m\"] = (\n",
        "    (future_serious.max(axis=1).fillna(0).astype(int)) |\n",
        "    (future_zb.max(axis=1).fillna(0).astype(int))\n",
        ").astype(int)\n",
        "\n",
        "# Past-only engineered features\n",
        "perf[\"dq_status_lag1\"] = g[\"dq\"].shift(1)\n",
        "perf[\"roll_3_dq\"] = g[\"is_dq\"].rolling(3, min_periods=1).sum().reset_index(level=0, drop=True)\n",
        "perf[\"roll_6_serious_dq\"] = g[\"is_serious_dq\"].rolling(6, min_periods=1).sum().reset_index(level=0, drop=True)\n",
        "\n",
        "perf = perf[valid].copy()\n",
        "perf = perf[perf[\"dq_status_lag1\"].notna()].copy()\n",
        "\n",
        "freddie_ds = perf.merge(orig[[\"loan_sequence_number\"]], on=\"loan_sequence_number\", how=\"left\")\n",
        "freddie_ds[\"year\"] = freddie_ds[\"monthly_reporting_period\"].dt.year\n",
        "\n",
        "print(\"Freddie dataset:\", freddie_ds.shape, \"pos_rate=\", freddie_ds[\"y_default_future_6m\"].mean())"
      ],
      "metadata": {
        "id": "8WUYD2xcMP1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols_f = [\"dq_status_lag1\",\"roll_3_dq\",\"roll_6_serious_dq\"]\n",
        "cat_cols_f = []\n",
        "\n",
        "train_f = freddie_ds[freddie_ds[\"year\"].isin([2022, 2023, 2024])].copy()\n",
        "test_f  = freddie_ds[freddie_ds[\"year\"].isin([2025])].copy()\n",
        "\n",
        "# If time-based exists, remove overlap loans from test\n",
        "if len(train_f) > 0 and len(test_f) > 0:\n",
        "    train_loans = set(train_f[\"loan_sequence_number\"].unique())\n",
        "    test_f = test_f[~test_f[\"loan_sequence_number\"].isin(train_loans)].copy()\n",
        "\n",
        "# Fallback if time-based test is empty\n",
        "if len(test_f) == 0:\n",
        "    print(\"WARNING: Time-based test split empty. Using LOAN-LEVEL split across full Freddie dataset.\")\n",
        "    all_loans = freddie_ds[\"loan_sequence_number\"].unique()\n",
        "    loans_tr, loans_tmp = train_test_split(all_loans, test_size=0.30, random_state=SEED)\n",
        "    loans_val, loans_te = train_test_split(loans_tmp, test_size=0.50, random_state=SEED)\n",
        "\n",
        "    train_f2 = freddie_ds[freddie_ds[\"loan_sequence_number\"].isin(loans_tr)].copy()\n",
        "    val_f    = freddie_ds[freddie_ds[\"loan_sequence_number\"].isin(loans_val)].copy()\n",
        "    test_f   = freddie_ds[freddie_ds[\"loan_sequence_number\"].isin(loans_te)].copy()\n",
        "else:\n",
        "    train_loans = train_f[\"loan_sequence_number\"].unique()\n",
        "    loans_tr, loans_val = train_test_split(train_loans, test_size=0.20, random_state=SEED)\n",
        "    train_f2 = train_f[train_f[\"loan_sequence_number\"].isin(loans_tr)].copy()\n",
        "    val_f    = train_f[train_f[\"loan_sequence_number\"].isin(loans_val)].copy()\n",
        "\n",
        "if len(train_f2)==0 or len(val_f)==0 or len(test_f)==0:\n",
        "    raise ValueError(f\"Bad Freddie splits: train={len(train_f2)} val={len(val_f)} test={len(test_f)}\")\n",
        "\n",
        "yf_tr   = train_f2[\"y_default_future_6m\"].astype(int).values\n",
        "yf_val  = val_f[\"y_default_future_6m\"].astype(int).values\n",
        "yf_test = test_f[\"y_default_future_6m\"].astype(int).values\n",
        "\n",
        "Xf_tr   = train_f2[num_cols_f + cat_cols_f].copy()\n",
        "Xf_val  = val_f[num_cols_f + cat_cols_f].copy()\n",
        "Xf_test = test_f[num_cols_f + cat_cols_f].copy()\n",
        "\n",
        "print(\"Freddie splits:\",\n",
        "      \"train\", Xf_tr.shape, \"val\", Xf_val.shape, \"test\", Xf_test.shape,\n",
        "      \"pos_rate_test\", yf_test.mean())"
      ],
      "metadata": {
        "id": "zOidfeYwMpC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build transformers safely (skip empty branches)\n",
        "transformers_f = []\n",
        "transformers_f.append((\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols_f))\n",
        "\n",
        "pre_f = ColumnTransformer(transformers=transformers_f, remainder=\"drop\")\n",
        "\n",
        "Xf_tr_t   = pre_f.fit_transform(Xf_tr)\n",
        "Xf_val_t  = pre_f.transform(Xf_val)\n",
        "Xf_test_t = pre_f.transform(Xf_test)\n",
        "\n",
        "neg, pos = int((yf_tr==0).sum()), int((yf_tr==1).sum())\n",
        "spw_f = neg / max(pos, 1)\n",
        "\n",
        "model_f = XGBClassifier(\n",
        "    n_estimators=5000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1,\n",
        "    eval_metric=\"aucpr\",\n",
        "    scale_pos_weight=spw_f,\n",
        "    tree_method=\"hist\"\n",
        ")\n",
        "\n",
        "model_f.fit(Xf_tr_t, yf_tr, eval_set=[(Xf_val_t, yf_val)], verbose=False)\n",
        "\n",
        "proba_f_val = model_f.predict_proba(Xf_val_t)[:, 1]\n",
        "thr_f = pick_threshold_max_f1(yf_val, proba_f_val)\n",
        "\n",
        "proba_f_test = model_f.predict_proba(Xf_test_t)[:, 1]\n",
        "freddie_metrics = evaluate_binary_plus(yf_test, proba_f_test, thr_f, \"Freddie_Default_XGB\")\n",
        "display(pd.DataFrame([freddie_metrics]))\n",
        "\n",
        "plot_roc(yf_test, proba_f_test, \"Freddie — ROC\")\n",
        "plot_pr(yf_test, proba_f_test, \"Freddie — PR\")\n",
        "plot_confusion(yf_test, proba_f_test, thr_f, f\"Freddie — Confusion (thr={thr_f:.3f})\")\n",
        "\n",
        "joblib.dump(\n",
        "    {\"pre\": pre_f, \"model\": model_f, \"num_cols\": num_cols_f, \"cat_cols\": cat_cols_f, \"threshold\": thr_f},\n",
        "    OUT_DIR / \"freddie_default_model.joblib\"\n",
        ")\n",
        "print(\"Saved Freddie model.\")"
      ],
      "metadata": {
        "id": "hbFnZOOAM3S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Upload manually (user selects file)\n",
        "uploaded = files.upload()  # pick fraud_oracle.csv from your computer\n",
        "\n",
        "# 2) Move uploaded CSVs into DATA_DIR\n",
        "for fn in uploaded.keys():\n",
        "    if fn.lower().endswith(\".csv\"):\n",
        "        src = WORKDIR / fn\n",
        "        dst = DATA_DIR / fn\n",
        "        if src.exists():\n",
        "            # overwrite if already exists\n",
        "            if dst.exists():\n",
        "                dst.unlink()\n",
        "            src.rename(dst)\n",
        "\n",
        "# 3) Find CSVs in DATA_DIR and choose fraud_oracle.csv if present\n",
        "csvs = list(DATA_DIR.glob(\"*.csv\"))\n",
        "if not csvs:\n",
        "    raise FileNotFoundError(\"No CSV found in DATA_DIR after upload.\")\n",
        "\n",
        "claims_path = None\n",
        "for p in csvs:\n",
        "    if p.name.lower() == \"fraud_oracle.csv\":\n",
        "        claims_path = p\n",
        "        break\n",
        "if claims_path is None:\n",
        "    # fallback: take the most recently modified csv\n",
        "    claims_path = max(csvs, key=lambda p: p.stat().st_mtime)\n",
        "\n",
        "# 4) Load\n",
        "claims = pd.read_csv(claims_path)\n",
        "print(\"Using claims file:\", claims_path.name)\n",
        "print(\"Claims shape:\", claims.shape)\n",
        "display(claims.head(5))"
      ],
      "metadata": {
        "id": "0yKqNz1aNGXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_COL = \"FraudFound_P\"\n",
        "if LABEL_COL not in claims.columns:\n",
        "    raise ValueError(f\"Claims label '{LABEL_COL}' not found. Columns: {list(claims.columns)}\")\n",
        "\n",
        "yc = claims[LABEL_COL].astype(int).values\n",
        "\n",
        "DROP_ALWAYS = [LABEL_COL]\n",
        "if \"PolicyNumber\" in claims.columns:\n",
        "    DROP_ALWAYS.append(\"PolicyNumber\")\n",
        "\n",
        "Xc_all = claims.drop(columns=DROP_ALWAYS, errors=\"ignore\")\n",
        "\n",
        "cat_cols_c = Xc_all.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "num_cols_c = Xc_all.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "Xc = Xc_all[num_cols_c + cat_cols_c].copy()\n",
        "\n",
        "print(\"Claims pos_rate:\", yc.mean())\n",
        "print(\"Num cols:\", len(num_cols_c), \"Cat cols:\", len(cat_cols_c))"
      ],
      "metadata": {
        "id": "w82mCMo8Tym_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
        "    Xc, yc, test_size=0.20, random_state=SEED, stratify=yc\n",
        ")\n",
        "Xc_tr, Xc_val, yc_tr, yc_val = train_test_split(\n",
        "    Xc_train, yc_train, test_size=0.20, random_state=SEED, stratify=yc_train\n",
        ")\n",
        "\n",
        "print(\"Claims splits:\",\n",
        "      \"train\", Xc_tr.shape, \"val\", Xc_val.shape, \"test\", Xc_test.shape,\n",
        "      \"pos_rate_test\", yc_test.mean())"
      ],
      "metadata": {
        "id": "Y2SL2Zs6UlqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformers_c = []\n",
        "if len(num_cols_c) > 0:\n",
        "    transformers_c.append((\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\"))]), num_cols_c))\n",
        "if len(cat_cols_c) > 0:\n",
        "    transformers_c.append((\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                                           (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat_cols_c))\n",
        "\n",
        "pre_c = ColumnTransformer(transformers=transformers_c, remainder=\"drop\")\n",
        "\n",
        "Xc_tr_t   = pre_c.fit_transform(Xc_tr)\n",
        "Xc_val_t  = pre_c.transform(Xc_val)\n",
        "Xc_test_t = pre_c.transform(Xc_test)\n",
        "\n",
        "neg, pos = int((yc_tr==0).sum()), int((yc_tr==1).sum())\n",
        "spw_c = neg / max(pos, 1)\n",
        "\n",
        "model_c = XGBClassifier(\n",
        "    n_estimators=2500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=SEED,\n",
        "    n_jobs=-1,\n",
        "    eval_metric=\"aucpr\",\n",
        "    scale_pos_weight=spw_c,\n",
        "    tree_method=\"hist\"\n",
        ")\n",
        "\n",
        "model_c.fit(Xc_tr_t, yc_tr, eval_set=[(Xc_val_t, yc_val)], verbose=False)\n",
        "\n",
        "proba_c_val = model_c.predict_proba(Xc_val_t)[:, 1]\n",
        "thr_c = pick_threshold_max_f1(yc_val, proba_c_val)\n",
        "\n",
        "proba_c_test = model_c.predict_proba(Xc_test_t)[:, 1]\n",
        "claims_metrics = evaluate_binary_plus(yc_test, proba_c_test, thr_c, \"Claims_Fraud_XGB\")\n",
        "display(pd.DataFrame([claims_metrics]))\n",
        "\n",
        "plot_roc(yc_test, proba_c_test, \"Claims — ROC\")\n",
        "plot_pr(yc_test, proba_c_test, \"Claims — PR\")\n",
        "plot_confusion(yc_test, proba_c_test, thr_c, f\"Claims — Confusion (thr={thr_c:.3f})\")\n",
        "\n",
        "joblib.dump(\n",
        "    {\"pre\": pre_c, \"model\": model_c, \"num_cols\": num_cols_c, \"cat_cols\": cat_cols_c, \"threshold\": thr_c, \"dropped\": DROP_ALWAYS},\n",
        "    OUT_DIR / \"claim_fraud_oracle_model.joblib\"\n",
        ")\n",
        "print(\"Saved Claims model.\")"
      ],
      "metadata": {
        "id": "N9gEVQ9tUoan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freddie scoring\n",
        "freddie_scored = freddie_ds.copy()\n",
        "Xf_all = freddie_scored[num_cols_f + cat_cols_f].copy()\n",
        "Xf_all_t = pre_f.transform(Xf_all)\n",
        "freddie_scored[\"p_default_future6m\"] = model_f.predict_proba(Xf_all_t)[:, 1]\n",
        "\n",
        "freddie_top = freddie_scored.sort_values(\"p_default_future6m\", ascending=False).head(200).copy()\n",
        "freddie_out = OUT_DIR / \"freddie_top200_default_future6m_cases.csv\"\n",
        "freddie_top.to_csv(freddie_out, index=False)\n",
        "\n",
        "# Claims scoring\n",
        "claims_scored = claims.copy()\n",
        "Xc_all2 = claims_scored.drop(columns=DROP_ALWAYS, errors=\"ignore\")\n",
        "Xc_all2 = Xc_all2[num_cols_c + cat_cols_c].copy()\n",
        "Xc_all2_t = pre_c.transform(Xc_all2)\n",
        "claims_scored[\"p_claim_suspicious\"] = model_c.predict_proba(Xc_all2_t)[:, 1]\n",
        "\n",
        "claims_top = claims_scored.sort_values(\"p_claim_suspicious\", ascending=False).head(200).copy()\n",
        "claims_out = OUT_DIR / \"claims_top200_suspicious_cases.csv\"\n",
        "claims_top.to_csv(claims_out, index=False)\n",
        "\n",
        "print(\"Saved outputs:\")\n",
        "print(\" -\", freddie_out)\n",
        "print(\" -\", claims_out)\n",
        "\n",
        "display(freddie_top[[\"loan_sequence_number\",\"p_default_future6m\",\"dq_status_lag1\",\"roll_6_serious_dq\"]].head(10))\n",
        "display(claims_top[[\"p_claim_suspicious\",\"FraudFound_P\"]].head(10))"
      ],
      "metadata": {
        "id": "MIIBzDXHUqyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_vqE9H8U765"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}