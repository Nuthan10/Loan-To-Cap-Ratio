{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyORgLbIZLFpa4BluYD8GEx/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuthan10/Loan-To-Cap-Ratio/blob/main/Insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas numpy scikit-learn xgboost joblib matplotlib\n",
        "\n",
        "import os, zipfile\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score, confusion_matrix,\n",
        "    roc_curve, auc, precision_recall_curve\n",
        ")\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 200)\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "WORKDIR = Path(\"/content\")\n",
        "DATA_DIR = WORKDIR / \"data\"\n",
        "OUT_DIR = WORKDIR / \"outputs\"\n",
        "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
        "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "def print_head(df, title, n=5):\n",
        "    print(f\"\\n--- {title} (rows={len(df):,}, cols={df.shape[1]}) ---\")\n",
        "    display(df.head(n))\n",
        "\n",
        "def require_columns(df: pd.DataFrame, cols, name=\"dataframe\"):\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"{name} is missing required columns: {missing}\")\n",
        "\n",
        "def evaluate_binary_percent(y_true, y_proba, threshold=0.5, model_name=\"model\"):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "    return {\n",
        "        \"model\": model_name,\n",
        "        \"threshold\": float(threshold),\n",
        "        \"accuracy_%\": round(accuracy_score(y_true, y_pred) * 100, 2),\n",
        "        \"precision\": round(precision_score(y_true, y_pred, zero_division=0), 4),\n",
        "        \"recall\": round(recall_score(y_true, y_pred, zero_division=0), 4),\n",
        "        \"f1\": round(f1_score(y_true, y_pred, zero_division=0), 4),\n",
        "        \"roc_auc\": round(roc_auc_score(y_true, y_proba), 4) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "        \"pr_auc\": round(average_precision_score(y_true, y_proba), 4) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "        \"positive_rate_%\": round(y_true.mean() * 100, 2),\n",
        "        \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist()\n",
        "    }\n",
        "\n",
        "print(\"Setup complete.\")\n"
      ],
      "metadata": {
        "id": "Ahi09htMNwwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    print(\"Uploaded:\", fn)\n",
        "\n",
        "for f in WORKDIR.glob(\"*\"):\n",
        "    if f.is_file() and f.suffix.lower() in [\".zip\", \".txt\", \".csv\"]:\n",
        "        target = DATA_DIR / f.name\n",
        "        if not target.exists():\n",
        "            f.rename(target)\n",
        "\n",
        "for z in DATA_DIR.glob(\"*.zip\"):\n",
        "    with zipfile.ZipFile(z, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(DATA_DIR)\n",
        "    print(\"Extracted:\", z.name)\n",
        "\n",
        "print(\"Files in data/:\")\n",
        "for f in sorted(DATA_DIR.glob(\"*\"))[:200]:\n",
        "    print(\" -\", f.name)\n"
      ],
      "metadata": {
        "id": "E8BjjCjHN58c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_freddie_file(path: Path, sep=\"|\"):\n",
        "    return pd.read_csv(path, sep=sep, header=None, dtype=str, engine=\"python\")\n",
        "\n",
        "all_files = list(DATA_DIR.glob(\"*\"))\n",
        "txt_candidates = [p for p in all_files if p.suffix.lower() in [\".txt\", \".csv\"]]\n",
        "txt_candidates = sorted(txt_candidates, key=lambda p: p.stat().st_size, reverse=True)\n",
        "\n",
        "orig_candidates = [p for p in txt_candidates if \"orig\" in p.name.lower() or \"origination\" in p.name.lower()]\n",
        "perf_candidates = [p for p in txt_candidates if any(k in p.name.lower() for k in [\"svcg\", \"servicing\", \"perf\", \"performance\", \"time\"])]\n",
        "\n",
        "orig_path = orig_candidates[0] if orig_candidates else (txt_candidates[0] if txt_candidates else None)\n",
        "perf_path = perf_candidates[0] if perf_candidates else (txt_candidates[1] if len(txt_candidates) > 1 else None)\n",
        "\n",
        "if orig_path is None or perf_path is None:\n",
        "    raise FileNotFoundError(\"Could not identify Freddie origination and performance files.\")\n",
        "\n",
        "print(\"Using origination file:\", orig_path.name)\n",
        "print(\"Using performance file:\", perf_path.name)\n",
        "\n",
        "orig_raw = read_freddie_file(orig_path, sep=\"|\")\n",
        "perf_raw = read_freddie_file(perf_path, sep=\"|\")\n",
        "\n",
        "print_head(orig_raw, \"Orig RAW\")\n",
        "print_head(perf_raw, \"Perf RAW\")\n"
      ],
      "metadata": {
        "id": "71pKXZTOOUuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FREDDIE_ORIG_COLS = [\n",
        "    \"credit_score\",\"first_payment_date\",\"first_time_homebuyer_flag\",\"maturity_date\",\"msa\",\n",
        "    \"mortgage_insurance_pct\",\"num_units\",\"occupancy_status\",\"orig_combined_ltv\",\"orig_dti\",\n",
        "    \"orig_upb\",\"orig_ltv\",\"orig_interest_rate\",\"channel\",\"prepayment_penalty_flag\",\n",
        "    \"amortization_type\",\"property_state\",\"property_type\",\"postal_code\",\"loan_sequence_number\",\n",
        "    \"loan_purpose\",\"orig_loan_term\",\"num_borrowers\",\"seller_name\",\"servicer_name\",\n",
        "    \"super_conforming_flag\"\n",
        "]\n",
        "\n",
        "FREDDIE_PERF_COLS = [\n",
        "    \"loan_sequence_number\",\"monthly_reporting_period\",\"current_actual_upb\",\"current_loan_delinquency_status\",\n",
        "    \"loan_age\",\"remaining_months_to_legal_maturity\",\"repurchase_flag\",\"modification_flag\",\"zero_balance_code\",\n",
        "    \"zero_balance_effective_date\",\"current_interest_rate\",\"current_deferred_upb\",\"due_date_of_last_paid_installment\",\n",
        "    \"mi_recoveries\",\"net_sales_proceeds\",\"non_mi_recoveries\",\"expenses\",\"legal_costs\",\"maintenance_and_preservation_costs\",\n",
        "    \"taxes_and_insurance\",\"misc_expenses\",\"actual_loss_calculation\",\"modification_cost\",\n",
        "    \"step_mod_flag\",\"deferred_payment_modification\",\"estimated_ltv\",\"zero_balance_removal_upb\",\"delinquency_due_to_disaster\",\n",
        "    \"borrower_assistance_status\",\"current_month_modification_cost\",\"interest_bearing_upb\"\n",
        "]\n",
        "\n",
        "def apply_cols_strict(df, cols, name):\n",
        "    if df.shape[1] != len(cols):\n",
        "        raise ValueError(\n",
        "            f\"{name} column count mismatch. Found {df.shape[1]} columns but expected {len(cols)}.\"\n",
        "        )\n",
        "    df = df.copy()\n",
        "    df.columns = cols\n",
        "    return df\n",
        "\n",
        "# Ensure orig_raw has the same number of columns as FREDDIE_ORIG_COLS by selecting the first N columns\n",
        "orig = apply_cols_strict(orig_raw.iloc[:, :len(FREDDIE_ORIG_COLS)], FREDDIE_ORIG_COLS, \"FREDDIE_ORIG_COLS\")\n",
        "# Ensure perf_raw has the same number of columns as FREDDIE_PERF_COLS by selecting the first N columns\n",
        "perf = apply_cols_strict(perf_raw.iloc[:, :len(FREDDIE_PERF_COLS)], FREDDIE_PERF_COLS, \"FREDDIE_PERF_COLS\")\n",
        "\n",
        "require_columns(perf, [\"loan_sequence_number\",\"monthly_reporting_period\",\"current_loan_delinquency_status\",\"zero_balance_code\"], \"Freddie performance\")\n",
        "\n",
        "perf[\"monthly_reporting_period\"] = pd.to_datetime(perf[\"monthly_reporting_period\"], format=\"%Y%m\", errors=\"coerce\")\n",
        "perf[\"zero_balance_effective_date\"] = pd.to_datetime(perf[\"zero_balance_effective_date\"], format=\"%Y%m\", errors=\"coerce\")\n",
        "\n",
        "if perf[\"monthly_reporting_period\"].isna().any():\n",
        "    raise ValueError(\"monthly_reporting_period has invalid dates.\")\n",
        "\n",
        "print_head(orig, \"Orig NAMED\")\n",
        "print_head(perf, \"Perf NAMED\")"
      ],
      "metadata": {
        "id": "xK_1k7mfOw8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numeric(s):\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "def map_dq(x):\n",
        "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
        "        return np.nan\n",
        "    x = str(x).strip()\n",
        "    return int(x) if x.isdigit() else np.nan\n",
        "\n",
        "perf = perf.sort_values([\"loan_sequence_number\", \"monthly_reporting_period\"]).copy()\n",
        "\n",
        "perf[\"dq_status_numeric\"] = perf[\"current_loan_delinquency_status\"].apply(map_dq)\n",
        "perf[\"zero_balance_code_num\"] = to_numeric(perf[\"zero_balance_code\"])\n",
        "\n",
        "perf[\"is_delinquent\"] = (perf[\"dq_status_numeric\"].fillna(0) >= 1).astype(int)\n",
        "perf[\"is_serious_delinquent\"] = (perf[\"dq_status_numeric\"].fillna(0) >= 3).astype(int)\n",
        "\n",
        "g = perf.groupby(\"loan_sequence_number\", sort=False)\n",
        "\n",
        "H = 6\n",
        "\n",
        "future_serious = [g[\"is_serious_delinquent\"].shift(-k) for k in range(1, H+1)]\n",
        "future_zb = [g[\"zero_balance_code_num\"].shift(-k).isin([3, 6, 9]).astype(int) for k in range(1, H+1)]\n",
        "\n",
        "perf[\"y_default_future_6m\"] = (\n",
        "    pd.concat(future_serious, axis=1).max(axis=1).fillna(0).astype(int)\n",
        "    | pd.concat(future_zb, axis=1).max(axis=1).fillna(0).astype(int)\n",
        ").astype(int)\n",
        "\n",
        "perf[\"rev_pos_in_loan\"] = g.cumcount(ascending=False)\n",
        "perf_snap = perf[perf[\"rev_pos_in_loan\"] >= H].copy()\n",
        "\n",
        "perf_snap[\"roll_3_dq\"] = g[\"is_delinquent\"].rolling(3, min_periods=1).sum().reset_index(level=0, drop=True)\n",
        "perf_snap[\"roll_6_serious_dq\"] = g[\"is_serious_delinquent\"].rolling(6, min_periods=1).sum().reset_index(level=0, drop=True)\n",
        "\n",
        "def streak(series):\n",
        "    out, s = [], 0\n",
        "    for v in series.astype(int).tolist():\n",
        "        s = s + 1 if v == 1 else 0\n",
        "        out.append(s)\n",
        "    return pd.Series(out, index=series.index)\n",
        "\n",
        "perf_snap[\"dq_streak\"] = g[\"is_delinquent\"].apply(streak).reset_index(level=0, drop=True)\n",
        "perf_snap[\"gap_flag_proxy\"] = (perf_snap[\"dq_streak\"] >= 2).astype(int)\n",
        "\n",
        "perf_snap[\"dq_status_lag1\"] = g[\"dq_status_numeric\"].shift(1)\n",
        "perf_snap = perf_snap[perf_snap[\"dq_status_lag1\"].notna()].copy()\n",
        "\n",
        "freddie_ds = perf_snap.merge(orig, on=\"loan_sequence_number\", how=\"left\")\n",
        "\n",
        "print(\"perf_snap shape:\", perf_snap.shape)\n",
        "print(\"y_default_future_6m positive rate:\", perf_snap[\"y_default_future_6m\"].mean())\n",
        "print_head(freddie_ds, \"Freddie Dataset (Leakage-Free)\")\n"
      ],
      "metadata": {
        "id": "PNmGeLCfPKGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "candidate_num = [\n",
        "    \"dq_status_lag1\",\"roll_3_dq\",\"roll_6_serious_dq\",\"dq_streak\",\"gap_flag_proxy\",\n",
        "    \"orig_upb\",\"orig_ltv\",\"orig_dti\",\"credit_score\",\"orig_interest_rate\",\"orig_loan_term\",\"orig_combined_ltv\"\n",
        "]\n",
        "candidate_cat = [\"property_state\",\"property_type\",\"occupancy_status\",\"loan_purpose\",\"channel\"]\n",
        "\n",
        "num_cols_f = [c for c in candidate_num if c in freddie_ds.columns]\n",
        "cat_cols_f = [c for c in candidate_cat if c in freddie_ds.columns]\n",
        "\n",
        "X = freddie_ds[num_cols_f + cat_cols_f].copy()\n",
        "y = freddie_ds[\"y_default_future_6m\"].astype(int).values\n",
        "loan_ids = freddie_ds[\"loan_sequence_number\"].values\n",
        "\n",
        "unique_loans = np.unique(loan_ids)\n",
        "train_loans, test_loans = train_test_split(unique_loans, test_size=0.2, random_state=SEED)\n",
        "train_loans, val_loans  = train_test_split(train_loans, test_size=0.2, random_state=SEED)\n",
        "\n",
        "train_mask = np.isin(loan_ids, train_loans)\n",
        "val_mask   = np.isin(loan_ids, val_loans)\n",
        "test_mask  = np.isin(loan_ids, test_loans)\n",
        "\n",
        "X_tr, y_tr = X.loc[train_mask], y[train_mask]\n",
        "X_val, y_val = X.loc[val_mask], y[val_mask]\n",
        "X_test, y_test_freddie = X.loc[test_mask], y[test_mask]\n",
        "\n",
        "pre_f = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler())]), num_cols_f),\n",
        "        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                          (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))]), cat_cols_f)\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "X_tr_t = pre_f.fit_transform(X_tr)\n",
        "X_val_t = pre_f.transform(X_val)\n",
        "X_test_t_freddie = pre_f.transform(X_test)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_tr_t, label=y_tr)\n",
        "dval   = xgb.DMatrix(X_val_t, label=y_val)\n",
        "dtest  = xgb.DMatrix(X_test_t_freddie)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"max_depth\": 4,\n",
        "    \"subsample\": 0.85,\n",
        "    \"colsample_bytree\": 0.85,\n",
        "    \"lambda\": 1.0,\n",
        "    \"seed\": SEED,\n",
        "    \"nthread\": -1\n",
        "}\n",
        "\n",
        "watchlist = [(dtrain, \"train\"), (dval, \"valid\")]\n",
        "\n",
        "booster_f = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=5000,\n",
        "    evals=watchlist,\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "proba_freddie = booster_f.predict(dtest)\n",
        "freddie_metrics = evaluate_binary_percent(y_test_freddie, proba_freddie, 0.5, \"Freddie_Default_Future6m_XGB\")\n",
        "display(pd.DataFrame([freddie_metrics]))\n",
        "\n",
        "joblib.dump(\n",
        "    {\"pre\": pre_f, \"model\": booster_f, \"num_cols\": num_cols_f, \"cat_cols\": cat_cols_f},\n",
        "    OUT_DIR / \"freddie_default_future6m_model.joblib\"\n",
        ")\n",
        "print(\"Saved Freddie model:\", OUT_DIR / \"freddie_default_future6m_model.joblib\")\n",
        "print(\"Best iteration:\", booster_f.best_iteration)\n"
      ],
      "metadata": {
        "id": "EWFvpn7fPkQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_class_balance(y, title):\n",
        "    y = np.asarray(y).astype(int)\n",
        "    counts = np.bincount(y, minlength=2)\n",
        "    labels = [\"Negative (0)\", \"Positive (1)\"]\n",
        "    plt.figure()\n",
        "    plt.bar(labels, counts)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc(y_true, y_proba, title):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_pr(y_true, y_proba, title):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
        "    ap = average_precision_score(y_true, y_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(recall, precision, label=f\"PR-AUC = {ap:.4f}\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion(y_true, y_proba, threshold, title):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_pred = (np.asarray(y_proba) >= threshold).astype(int)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.title(f\"{title} (thr={threshold})\")\n",
        "    plt.colorbar()\n",
        "    plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n",
        "    plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_score_dist(y_true, y_proba, title):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_proba = np.asarray(y_proba)\n",
        "    plt.figure()\n",
        "    plt.hist(y_proba[y_true == 0], bins=30, alpha=0.7, label=\"Class 0\")\n",
        "    plt.hist(y_proba[y_true == 1], bins=30, alpha=0.7, label=\"Class 1\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted probability\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_xgb_training_curve(xgb_model, title):\n",
        "    if not hasattr(xgb_model, \"evals_result_\") or not xgb_model.evals_result_:\n",
        "        print(\"No evals_result_ found.\")\n",
        "        return\n",
        "    res = xgb_model.evals_result_\n",
        "    key0 = list(res.keys())[0]\n",
        "    metric0 = list(res[key0].keys())[0]\n",
        "    vals = res[key0][metric0]\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(vals)), vals)\n",
        "    plt.title(f\"{title}\\n({key0} / {metric0})\")\n",
        "    plt.xlabel(\"Boosting round\")\n",
        "    plt.ylabel(metric0)\n",
        "    plt.show()\n",
        "\n",
        "def plot_xgb_feature_importance(xgb_model, feature_names=None, top_n=20, title=\"Top Feature Importances\"):\n",
        "    booster = xgb_model.get_booster()\n",
        "    score = booster.get_score(importance_type=\"gain\")\n",
        "    if not score:\n",
        "        print(\"No feature importance available.\")\n",
        "        return\n",
        "    items = sorted(score.items(), key=lambda kv: kv[1], reverse=True)[:top_n]\n",
        "    feats = [k for k, _ in items]\n",
        "    vals = [v for _, v in items]\n",
        "    if feature_names is not None:\n",
        "        def map_name(f):\n",
        "            if f.startswith(\"f\"):\n",
        "                idx = int(f[1:])\n",
        "                if 0 <= idx < len(feature_names):\n",
        "                    return feature_names[idx]\n",
        "            return f\n",
        "        feats = [map_name(f) for f in feats]\n",
        "    plt.figure()\n",
        "    y_pos = np.arange(len(feats))\n",
        "    plt.barh(y_pos, vals)\n",
        "    plt.yticks(y_pos, feats)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(title + \" (gain)\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "xQ4SWQJ5PwRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_class_balance(y_test_freddie, \"Freddie — Test Class Balance (Future 6M Default)\")\n",
        "plot_roc(y_test_freddie, proba_freddie, \"Freddie — ROC Curve\")\n",
        "plot_pr(y_test_freddie, proba_freddie, \"Freddie — Precision–Recall Curve\")\n",
        "plot_confusion(y_test_freddie, proba_freddie, threshold=0.5, title=\"Freddie — Confusion Matrix\")\n",
        "plot_score_dist(y_test_freddie, proba_freddie, \"Freddie — Score Distribution\")\n",
        "plot_xgb_training_curve(xgb_f, \"Freddie — Validation AUC Over Boosting Rounds\")\n",
        "\n",
        "try:\n",
        "    feature_names_f = pre_f.get_feature_names_out()\n",
        "except Exception:\n",
        "    feature_names_f = None\n",
        "\n",
        "plot_xgb_feature_importance(xgb_f, feature_names=feature_names_f, top_n=20, title=\"Freddie — Top Feature Importances\")\n"
      ],
      "metadata": {
        "id": "afHI9McQfnB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    print(\"Uploaded:\", fn)\n",
        "\n",
        "for f in WORKDIR.glob(\"*.csv\"):\n",
        "    target = DATA_DIR / f.name\n",
        "    if not target.exists():\n",
        "        f.rename(target)\n",
        "\n",
        "csvs = list(DATA_DIR.glob(\"*.csv\"))\n",
        "if not csvs:\n",
        "    raise FileNotFoundError(\"No CSV found.\")\n",
        "\n",
        "claims_path = csvs[0]\n",
        "claims = pd.read_csv(claims_path)\n",
        "print(\"Using claims file:\", claims_path.name)\n",
        "print_head(claims, \"Claims RAW\")\n"
      ],
      "metadata": {
        "id": "5DVqA5L_fr-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_tr_t, label=y_tr)\n",
        "dval   = xgb.DMatrix(X_val_t, label=y_val)\n",
        "dtest  = xgb.DMatrix(X_test_t_claims)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"max_depth\": 4,\n",
        "    \"subsample\": 0.85,\n",
        "    \"colsample_bytree\": 0.85,\n",
        "    \"lambda\": 1.0,\n",
        "    \"seed\": SEED,\n",
        "    \"nthread\": -1\n",
        "}\n",
        "\n",
        "watchlist = [(dtrain, \"train\"), (dval, \"valid\")]\n",
        "\n",
        "booster_c = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=5000,\n",
        "    evals=watchlist,\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "proba_claims = booster_c.predict(dtest)\n",
        "claims_metrics = evaluate_binary_percent(y_test_claims, proba_claims, 0.5, \"Claims_Fraud_XGB\")\n",
        "display(pd.DataFrame([claims_metrics]))\n",
        "\n",
        "joblib.dump(\n",
        "    {\"pre\": pre_c, \"model\": booster_c, \"num_cols\": num_cols_c, \"cat_cols\": cat_cols_c},\n",
        "    OUT_DIR / \"claim_suspicious_model.joblib\"\n",
        ")\n",
        "print(\"Saved Claims model:\", OUT_DIR / \"claim_suspicious_model.joblib\")\n",
        "print(\"Best iteration:\", booster_c.best_iteration)\n"
      ],
      "metadata": {
        "id": "NBRHBRvrh6L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "japJM6T3iv1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}