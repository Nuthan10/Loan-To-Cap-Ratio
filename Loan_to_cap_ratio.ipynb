{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPGLAcg8/RctAxw7IgcU7Sd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuthan10/Loan-To-Cap-Ratio/blob/main/Loan_to_cap_ratio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cURtihY6cjs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install xgboost catboost lightgbm shap kagglehub"
      ],
      "metadata": {
        "id": "bYZJwmNGckUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import shap\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "khq33hsHckwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) DATA LOADING\n",
        "#    Prefer Kaggle; fallback to manual upload or synthetic"
      ],
      "metadata": {
        "id": "1ffjU_xscwh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def try_load_kaggle():\n",
        "    try:\n",
        "        import kagglehub\n",
        "        path = kagglehub.dataset_download(\"altruistdelhite04/loan-prediction-problem-dataset\")\n",
        "        csv_path = os.path.join(path, \"train.csv\")\n",
        "        if os.path.exists(csv_path):\n",
        "            print(\"âœ… Loaded Kaggle dataset:\", csv_path)\n",
        "            return pd.read_csv(csv_path)\n",
        "    except Exception as e:\n",
        "        print(\"â„¹ï¸ Kaggle download unavailable:\", e)\n",
        "    return None\n",
        "\n",
        "def try_manual_upload():\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"ðŸ“¥ Please upload your Kaggle train.csv\")\n",
        "        up = files.upload()\n",
        "        name = list(up.keys())[0]\n",
        "        print(\"âœ… Loaded manual upload:\", name)\n",
        "        return pd.read_csv(name)\n",
        "    except Exception as e:\n",
        "        print(\"â„¹ï¸ Manual upload skipped/unavailable:\", e)\n",
        "    return None\n",
        "def make_synthetic_kaggle_like(n=1000):\n",
        "    print(\"âš™ï¸ Using synthetic Kaggle-like dataset.\")\n",
        "    df = pd.DataFrame({\n",
        "        'LoanAmount': np.random.randint(100, 500, n),  # in thousands\n",
        "        'ApplicantIncome': np.random.randint(20000, 150000, n),\n",
        "        'Gender': np.random.choice(['Male', 'Female'], n),\n",
        "        'Married': np.random.choice(['Yes', 'No'], n),\n",
        "        'Education': np.random.choice(['Graduate', 'Not Graduate'], n),\n",
        "        'Self_Employed': np.random.choice(['Yes', 'No'], n),\n",
        "        'Credit_History': np.random.choice([1.0, 0.0], n),\n",
        "        'Loan_Status': np.random.choice(['Y', 'N'], n, p=[0.7, 0.3])\n",
        "    })\n",
        "    return df\n",
        "\n",
        "df = try_load_kaggle()\n",
        "if df is None:\n",
        "    df = try_manual_upload()\n",
        "if df is None:\n",
        "    df = make_synthetic_kaggle_like(n=1200)\n"
      ],
      "metadata": {
        "id": "iFLprZ_EcwME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) CLEANING + LTC FEATURE"
      ],
      "metadata": {
        "id": "JR2WTC8bdrE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "needed = ['LoanAmount','ApplicantIncome','Credit_History','Gender','Married',\n",
        "          'Education','Self_Employed','Loan_Status']\n",
        "for col in needed:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "for c in ['LoanAmount','ApplicantIncome','Credit_History']:\n",
        "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].median())\n",
        "df['ApplicantIncome'] = df['ApplicantIncome'].fillna(df['ApplicantIncome'].median())\n",
        "df['Credit_History'] = df['Credit_History'].fillna(1.0)\n",
        "\n",
        "np.random.seed(RANDOM_STATE)\n",
        "df['cap_of_insurance'] = np.clip(\n",
        "    np.random.normal(loc=250000, scale=60000, size=len(df)), 50000, None\n",
        ")\n",
        "df['type_of_insurance'] = np.random.choice(['Health', 'Life', 'Property'], size=len(df))\n",
        "df['loan_to_cap_ratio'] = (df['LoanAmount'] * 1000) / df['cap_of_insurance']\n",
        "df['loan_to_cap_ratio'] = df['loan_to_cap_ratio'].astype(float)"
      ],
      "metadata": {
        "id": "kDaK2XfKc-WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding"
      ],
      "metadata": {
        "id": "_8A6U_ieePg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_cols = [col for col in df.columns if 'Loan_ID' in col or 'loan_id' in col.lower()]\n",
        "df = df.drop(columns=id_cols, errors='ignore')\n",
        "if 'Loan_Status' in df.columns:\n",
        "    df['Loan_Status'] = df['Loan_Status'].map({'Y': 0, 'N': 1})\n",
        "object_cols = df.select_dtypes(include=['object']).columns\n",
        "if len(object_cols) > 0:\n",
        "    df = pd.get_dummies(df, columns=object_cols, drop_first=True)"
      ],
      "metadata": {
        "id": "Y4z2qnkPkDLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/test split"
      ],
      "metadata": {
        "id": "Vth2VabUedHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Loan_Status' in df.columns:\n",
        "    X = df.drop(columns=['Loan_Status'])\n",
        "    y = df['Loan_Status']\n",
        "else:\n",
        "    X = df.copy()\n",
        "    y = None\n",
        "\n",
        "if y is not None:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "\n",
        "    num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
        "    X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "    X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
        "else:\n",
        "    print(\"No target variable found. Skipping split.\")\n"
      ],
      "metadata": {
        "id": "0ovLXc-SeYcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) MODEL CONFIGURATIONS"
      ],
      "metadata": {
        "id": "opW8T2GifBmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "    'LogisticRegression': [\n",
        "        LogisticRegression(max_iter=500, class_weight='balanced', n_jobs=-1, random_state=RANDOM_STATE),\n",
        "    ],\n",
        "    'RandomForest': [\n",
        "        RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=RANDOM_STATE),\n",
        "    ],\n",
        "    'XGBoost': [\n",
        "        XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.08, subsample=0.9,\n",
        "                      colsample_bytree=0.9, eval_metric='logloss', n_jobs=-1, random_state=RANDOM_STATE),\n",
        "    ],\n",
        "    'CatBoost': [\n",
        "        CatBoostClassifier(iterations=400, depth=6, learning_rate=0.08, verbose=0, random_state=RANDOM_STATE)\n",
        "    ],\n",
        "    'LightGBM': [\n",
        "        LGBMClassifier(n_estimators=400, max_depth=-1, learning_rate=0.08, subsample=0.9,\n",
        "                       colsample_bytree=0.9, n_jobs=-1, random_state=RANDOM_STATE)\n",
        "    ],\n",
        "    'GradientBoosting': [\n",
        "        GradientBoostingClassifier(n_estimators=400, learning_rate=0.08, max_depth=5, random_state=RANDOM_STATE)\n",
        "    ],\n",
        "    'HistGradientBoosting': [\n",
        "        HistGradientBoostingClassifier(max_iter=400, learning_rate=0.08, max_depth=5, random_state=RANDOM_STATE)\n",
        "    ],\n",
        "    'ExtraTrees': [\n",
        "        ExtraTreesClassifier(n_estimators=400, n_jobs=-1, random_state=RANDOM_STATE)\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "UCbyqo9kejc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) TRAINING & LIVE METRICS"
      ],
      "metadata": {
        "id": "hCH-HfDUfPuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metrics(y_true, y_pred, y_proba):\n",
        "    acc = accuracy_score(y_true, y_pred) * 100.0\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    roc = roc_auc_score(y_true, y_proba)\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_proba)\n",
        "    pr_auc = auc(rec, prec)\n",
        "    return acc, f1, roc, pr_auc\n",
        "\n",
        "if y is not None:\n",
        "    all_runs = []\n",
        "    best_by_model = {}\n",
        "    for family, configs in model_configs.items():\n",
        "        family_best = None\n",
        "        for i, model in enumerate(configs, start=1):\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") \\\n",
        "                else model.decision_function(X_test)\n",
        "            acc, f1, roc, pr_auc = eval_metrics(y_test, y_pred, y_proba)\n",
        "            row = {\n",
        "                'Model': family,\n",
        "                'Run': i,\n",
        "                'Accuracy (%)': round(acc, 2),\n",
        "                'F1': round(f1, 4),\n",
        "                'ROC_AUC': round(roc, 4),\n",
        "                'PR_AUC': round(pr_auc, 4),\n",
        "                'Estimator': model\n",
        "            }\n",
        "            all_runs.append(row)\n",
        "            if (family_best is None) or (roc > family_best['ROC_AUC']):\n",
        "                family_best = row\n",
        "                best_by_model[family] = family_best\n",
        "    print(\"\\nBest model per family:\")\n",
        "    for fam, info in best_by_model.items():\n",
        "        print(f\"{fam}: Acc={info['Accuracy (%)']} F1={info['F1']} ROC_AUC={info['ROC_AUC']} PR_AUC={info['PR_AUC']}\")\n",
        "\n",
        "    # SHAP EXPLAINER for model with max ROC_AUC across all families\n",
        "    top_row = max(all_runs, key=lambda x: x['ROC_AUC'])\n",
        "    best_model = top_row['Estimator']\n",
        "    print(f\"\\nUsing SHAP to explain: {top_row['Model']} (ROC_AUC={top_row['ROC_AUC']})\")\n",
        "\n",
        "    # Pick small subset for SHAP to avoid memory issues\n",
        "    X_shap = X_train.sample(200, random_state=RANDOM_STATE) if X_train.shape[0] > 200 else X_train\n",
        "\n",
        "    try:\n",
        "        explainer = shap.Explainer(best_model, X_shap)\n",
        "        shap_values = explainer(X_shap)\n",
        "        shap.summary_plot(shap_values, X_shap, show=True)\n",
        "    except Exception as e:\n",
        "        print(f\"SHAP could not explain {top_row['Model']} automatically: {e}\")\n",
        "        print(\"Try using TreeExplainer or KernelExplainer for this model manually.\")\n",
        "else:\n",
        "    print(\"Skipping model training, no target variable.\")"
      ],
      "metadata": {
        "id": "nflfiClthU-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) PLOTS (computed from live results)"
      ],
      "metadata": {
        "id": "ZWIwdooRmfWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xmGoiWGmfEQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5a) Accuracy across runs (line plot per family)"
      ],
      "metadata": {
        "id": "HiDgmwFImlRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(all_runs)  # <-- Add this if not done already\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for fam in results_df['Model'].unique():\n",
        "    sub = results_df[results_df['Model']==fam]\n",
        "    plt.plot(sub['Run'], sub['Accuracy (%)'], marker='o', label=fam)\n",
        "plt.title(\"Accuracy (%) Across Runs per Model Family\")\n",
        "plt.xlabel(\"Run\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RRMMmRVgmicQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5b) ROC & PR curves for the best run of each family"
      ],
      "metadata": {
        "id": "NoAUVzdvmxyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_pr_for_best():\n",
        "    from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc\n",
        "    plt.figure(figsize=(9,6))\n",
        "    for fam, row in best_by_model.items():\n",
        "        model = row['Estimator']\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_proba = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            y_proba = model.decision_function(X_test)\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "        roc_val = roc_auc_score(y_test, y_proba)\n",
        "        plt.plot(fpr, tpr, label=f\"{fam} (AUC={roc_val:.2f})\")\n",
        "    plt.plot([0,1],[0,1],'k--')\n",
        "    plt.title(\"ROC Curves (Best Run per Model)\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(9,6))\n",
        "    for fam, row in best_by_model.items():\n",
        "        model = row['Estimator']\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_proba = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            y_proba = model.decision_function(X_test)\n",
        "        prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
        "        pr_val = auc(rec, prec)\n",
        "        plt.plot(rec, prec, label=f\"{fam} (PR AUC={pr_val:.2f})\")\n",
        "    plt.title(\"Precision-Recall Curves (Best Run per Model)\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_pr_for_best()"
      ],
      "metadata": {
        "id": "UUNDL0PNmpZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5c) Confusion matrices for the best run of each family"
      ],
      "metadata": {
        "id": "GkfS_ACEnKn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from itertools import product\n",
        "def plot_confusions_for_best():\n",
        "    fams = list(best_by_model.keys())\n",
        "    n = len(fams)\n",
        "    cols = 3\n",
        "    rows = int(np.ceil(n/cols))\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(12, 4*rows))\n",
        "    axes = axes.flatten()\n",
        "    for ax, fam in zip(axes, fams):\n",
        "        model = best_by_model[fam]['Estimator']\n",
        "        y_pred = model.predict(X_test)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "        ax.set_title(f\"{fam} - Best Run CM\")\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"Actual\")\n",
        "        tick_marks = np.arange(cm.shape[0])\n",
        "        ax.set_xticks(tick_marks)\n",
        "        ax.set_yticks(tick_marks)\n",
        "        for (r, c) in product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            color = 'white' if cm[r, c] > cm.max() / 2 else 'black'\n",
        "            ax.text(c, r, cm[r, c], ha='center', va='center', color=color)\n",
        "    for j in range(len(fams), len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_confusions_for_best()"
      ],
      "metadata": {
        "id": "B86iq-fVnEKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uXrhRC0nSjp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}